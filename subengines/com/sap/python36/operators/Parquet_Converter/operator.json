{
    "description": "Parquet_Converter",
    "component": "com.sap.system.python3Operator",
    "versionStatus": "active",
    "inports": [
        {
            "name": "input1",
            "type": "message"
        }
    ],
    "outports": [
        {
            "name": "output",
            "type": "message"
        },
        {
            "name": "stop",
            "type": "message"
        }
    ],
    "iconsrc": "python.svg",
    "config": {
        "script": "## Custom code build in Base Python3 operator to append headers in csv file.\n## Author: Shristi Drolia\n##         Manish Kumar\n## Publish Date: \n## Version : 1.0\n# Import Python Libraries\nimport io\nfrom io import StringIO\nfrom io import BytesIO\nimport csv\nimport pandas as pd\nimport json\nimport numpy as np\nimport datetime\nimport time\nimport uuid\n\n\n# read data coming from SLT operator\ndef on_input(inData):\n# Formulation of date and time variable which will be used in filename\n    mytimestamp = datetime.datetime.now()\n    mydate = datetime.datetime.strftime(mytimestamp, \"%Y%m%d\")\n    mytime = datetime.datetime.strftime(mytimestamp, \"%H%M%S%f\")\n    mydatetime = mydate+\"_\"+mytime+\"_\"+str(uuid.uuid4())\n    \n# read body    \n    data = StringIO(inData.body)\n# read attribute    \n    attr = inData.attributes\n    \n# columns extraction from json attributes    \n    ABAPKEY = attr['ABAP']\n\n# col variable to store column names\n    col= []\n\n# last batch determination \n    if('message.lastBatch' in attr):\n        MSG = '1'\n    else:\n        MSG = '0'\n# sending stop signal once last batch is detected    \n    if(MSG == '1'):\n        api.send(\"stop\", \"stop\")\n        \n    else:    \n# preparing list of columns         \n        for columnname in ABAPKEY['Fields']:\n            col.append(columnname['Name'])\n# dataframe with columns and data            \n        df = pd.read_csv(data, index_col=False, names=col, dtype = 'str')\n# dataframe consversion to csv with header attributes\n        df_csv = df.to_parquet()\n\n#attribute to store date and time and counter \n        attr['mydatetime'] = mydatetime\n        \n        \n# determine if the load is in initail phase or cdc and based on that folder name is determined\n        if(df['IUUC_OPERATION'].iloc[0] in ('I', 'U', 'D')):\n            attr['foldername'] = 'CDC_DI'\n            \n\n# sending csv as output            \n            api.send(\"output\", api.Message(attributes = attr, body=df_csv))\n        \n        else:\n            attr['foldername'] = mydate\n# sending csv as output            \n            api.send(\"output\", api.Message(attributes = attr, body=df_csv))\n# reading next batch of data             \napi.set_port_callback(\"input1\", on_input)",
        "scriptReference": "script.py"
    },
    "tags": {
        "parquet": "1.0.0",
        "python36": "",
        "tornado": "5.0.2"
    }
}