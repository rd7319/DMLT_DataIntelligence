{
    "description": "Copy HIVE Operator",
    "component": "com.sap.system.python3Operator",
    "versionStatus": "active",
    "inports": [
        {
            "name": "FileData",
            "type": "message.file"
        },
        {
            "name": "intrigger",
            "type": "string"
        }
    ],
    "outports": [
        {
            "name": "output",
            "type": "string"
        }
    ],
    "icon": "puzzle-piece",
    "config": {
        "$type": "http://sap.com/vflow/Copy HIVE Operator.configSchema.json",
        "Query": "",
        "Query_mode": "${query_mode}",
        "database": "dsmodel_validation",
        "hive_host": "datavault-e3.core.unionbank.com",
        "hive_port": 10000,
        "jks_file": "cm-auto-global_truststore",
        "key_tab": "dvmrmsvc01.headless",
        "krb_conf": "krb5",
        "principal": "hive/datavault-e3.core.unionbank.com@CORE.UNIONBANK.COM",
        "script": "import pandas as pd\r\nfrom io import StringIO\r\nfrom io import BytesIO\r\nfrom subprocess import call\r\nfrom hivejdbc import connect\r\n\r\n#function to take action on input\r\ndef on_input(intrigger):\r\n    hive_function(intrigger)\r\n\r\n#function to extract first item from the list\r\ndef Extract(lst):\r\n    return [item[0] for item in lst]\r\n    \r\n#Function to set up connection to Hive\r\ndef get_connection():\r\n    conn = connect(host = api.config.hive_host,\r\n                   port = api.config.hive_port,\r\n                   database = api.config.database,\r\n                   driver = '/usr/local/hive-jdbc-2.1.1-standalone.jar',\r\n                   ssl = api.config.ssl_enabled,\r\n                   trust_store = '/vrep/vflow/subengines/com/sap/python36/operators/ubp/com/sap/python36/hive/cm-auto-global_truststore.jks',\r\n                   trust_password = '11XBYhbeufNalGo8hs0ZvZBXw8nNu6E3yxM3THkaYOO',\r\n                   principal = api.config.principal,\r\n                   krb5_conf = '/vrep/vflow/subengines/com/sap/python36/operators/ubp/com/sap/python36/hive/krb5.conf',\r\n                   user_principal = api.config.user_principal,\r\n                   user_keytab = '/vrep/vflow/subengines/com/sap/python36/operators/ubp/com/sap/python36/hive/dvmrmsvc01.headless.keytab')\r\n    return conn\r\n    \r\n#Function to prepare query\r\ndef get_query():\r\n    return api.config.Query\r\n    \r\n#Function to Prepare Insert query for bulk load from file data\r\ndef get_insert_bulk_query(intrigger):\r\n    data = StringIO(intrigger.body.decode(\"utf-8\"))\r\n    df = pd.read_csv(data, index_col=False, dtype = 'str')\r\n    \r\n    #first element will be header and last element will be blank so not considering them when we conver Dataframe to csv\r\n    df_1=df.to_csv(index=False).split('\\n')[1:-1]\r\n        \r\n    #getting the column count for each file given\r\n    column_count=int(len(str(df_1).split(','))/len(df_1))\r\n\r\n    #generating data in necessary format\r\n    data=''\r\n    final_data=[]\r\n    final_data1=[]\r\n    for row in range(0,len(df_1)):\r\n        for value in range(0,column_count):\r\n            if value == 0:\r\n                data=(str(df_1[row]).split(',')[value])\r\n                data='('+data\r\n                final_data.append(data)\r\n            elif value == (column_count-1):\r\n                data=(str(df_1[row]).split(',')[value])\r\n                data=data+')'\r\n                final_data.append(data)\r\n            else:\r\n                data=(str(df_1[row]).split(',')[value])\r\n                final_data.append(data)\r\n    final_data=str(final_data).replace(\"'(\",\"('\").replace(\")'\",\"')\")   \r\n    final_data1.append(final_data)\r\n                \r\n    #concatenate all the records into insert query\r\n    insert_query = 'insert into table test5 values '+','.join(final_data1)\r\n    insert_query=insert_query.replace('[','').replace(']','')\r\n    \r\n    return insert_query\r\n\r\n#Function to get the result of the query\r\ndef get_result(query,cur):\r\n        #Incase of queries - INSERT and CREATE, there is no resultset and hence seperating the logic\r\n    if((query.split()[0] == \"SELECT\") or (query.split()[0] == \"DESCRIBE\") or (query.split()[0] == \"SHOW\")):\r\n        \r\n        #fetching the resulset recieved after query execution\r\n        resultList = cur.fetchall()\r\n        \r\n        string = \"\"\r\n        \r\n        #attaching the header to the resultset - derived based on regular expression on DESCRIBE\r\n        if(query.split()[0]==\"SELECT\"):\r\n            if(int(query.count('SELECT *')) == 1 and int(query.count('JOIN')) \u003c 1):\r\n            \r\n                #Fetching the tablename from the query inputtted\r\n                tablename = query.split(\" \")[3:][0]\r\n                desc_query = \"DESCRIBE\" + \" \" +  tablename\r\n            \r\n                #executing the DESCRIBE to getch the column names\r\n                cur.execute(desc_query)\r\n                header = cur.fetchall()\r\n                \r\n                #attaching the header to the final dataset\r\n                string = ','.join(map(str, Extract(header))) + \"\\n\"\r\n                \r\n                #adding teh delimiter , to the resultset derived from the query inputted\r\n                for x in resultList:\r\n                    for y in x:\r\n                        string = string + str(y) + \",\" ##api.config.delimiter ## Delimiter to separate Hive columns in output\r\n                    string = string.rstrip(',') + \"\\n\"\r\n                \r\n                #sending the ouput to the terminal    \r\n                #api.send(\"output\",string)\r\n                \r\n            #Incase the input query is select c1,c2,... statement - attaching the headers by parsing the query\r\n            elif(int(query.count('SELECT *')) == 0 and int(query.count('JOIN')) \u003c 1):\r\n                #copy query by trimming spaces\r\n                query_copy = \"\".join(query.split())\r\n                #fetch the index of 'FROM' in the query\r\n                index_from = query_copy.index(\"FROM\")\r\n                #fetch columns from query which will be between select and from \r\n                column_str = query_copy[6:index_from]\r\n                #converting the column names in to list\r\n                column_names = column_str.split(\",\")\r\n                #attaching the header to the final dataset\r\n                string = ','.join(column_names) + \"\\n\"\r\n                #adding teh delimiter , to the resultset derived from the query inputted\r\n                for x in resultList:\r\n                    for y in x:\r\n                        string = string + str(y) + \",\" ##api.config.delimiter ## Delimiter to separate Hive columns in output\r\n                    string = string.rstrip(',') + \"\\n\"\r\n            #Incase the input query is not a SELECT * or select c1,c2,... statement - we don't need to attach the headers    \r\n            else:\r\n                for x in resultList:\r\n                    for y in x:\r\n                        string = string + str(y) + \",\" ##api.config.delimiter ## Delimiter to separate Hive columns in output\r\n                    string = string.rstrip(',') + \"\\n\"\r\n        #Incase of Show or describe query - no need of attaching the headers\r\n        else:\r\n            for x in resultList:\r\n                    for y in x:\r\n                        string = string + str(y) + \",\" ##api.config.delimiter ## Delimiter to separate Hive columns in output\r\n                    string = string.rstrip(',') + \"\\n\"\r\n    #incase of the INSERT, CREATE, SET queries - since there is no resultset to be returned to output, program is sending a successful message.\r\n    else:\r\n        string = 'Executed successfully'\r\n    \r\n    return string\r\n    \r\n#Hive function to connect, query and process the data\r\ndef hive_function(intrigger):\r\n    conn = get_connection()\r\n    #Using Hive JDBC establishing the connection to the HIVE\r\n    \r\n    if api.config.Query_mode == 'insert_bulk':\r\n        #prepare query\r\n        inSql = get_insert_bulk_query(intrigger)\r\n    else:\r\n        inSql = get_query()\r\n        \r\n        \r\n    #creating cursor to Hive connection\r\n    cur = conn.cursor()\r\n    \r\n    #Using the cursor exceuting the query from the input\r\n    cur.execute(inSql)\r\n    \r\n    #Casing the query for processing\r\n    query = inSql.upper()\r\n    \r\n    api.send(\"output\",get_result(query,cur))\r\n\r\nif api.config.Query_mode == 'insert_bulk':\r\n    api.set_port_callback(\"FileData\", on_input)\r\nelse:\r\n    api.set_port_callback(\"intrigger\", on_input)",
        "ssl_enabled": true,
        "user_principal": "dvmrmsvc01@CORE.UNIONBANK.COM"
    },
    "tags": {
        "hive_python": "",
        "python36": "\"\"",
        "tornado": "5.0.2"
    }
}